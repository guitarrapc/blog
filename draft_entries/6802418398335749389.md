---
Title: EKS AutoModeは通常モードと何が違うのか
EditURL: https://blog.hatena.ne.jp/guitarrapc_tech/guitarrapc-tech.hatenablog.com/atom/entry/6802418398335749389
PreviewURL: https://tech.guitarrapc.com/draft/entry/ln7wiHg0Cs_VGd1Q8TUWIQBJH6k
Draft: true
---

2024/12/1にre:Inventで[発表](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-eks-auto-mode/)されたEKS AutoModeと通常モードの違いについてまとめます。
AWSとしては、EKS AutoModeを今後EKSを構築する時のスタンダードにしていきたいんだろうなと感じます。ただ、AutoModeはEKS AddonやKarpenterをはじめ、組み込みコンポーネントが隠蔽されており違いを知っておかないと戸惑う感じがあります。

本記事ではEKS AutoModeを構築、通常モードで組むようなKarpenter操作を加えて違いを見ていきます。

[:contents]

# EKS AutoModeのコンセプト

EKS AutoModeはクラスター管理をAWSに[オフロードしてアプリケーション開発にフォーカスできるようにする](https://aws.amazon.com/jp/blogs/containers/getting-started-with-amazon-eks-auto-mode/)というのがコンセプトとされています。

その例として、次の図が示されています。これまでのEKSではAddOnsやEC2インスタンスをユーザー管理していたのに対して、Auto Modeはストレージ/コンピュート/ロードバランサー管理をAWSが担保しEC2にも関与するようになっています。

> ![image](https://github.com/user-attachments/assets/7199547b-cfd5-4db4-a4da-7fa790fcbe63)
>
> Before Auto Mode

> ![image](https://github.com/user-attachments/assets/431bfd3e-b446-44a8-9c33-97ea5d83a61b)
>
> After Auto Mode

# コンセプトから受ける印象と実情

EKS AutoModeはこのコンセプト図から次のような印象を得ます。

* EKS AddonsはAWSが管理するためユーザーは導入不要になった
* EC2のオートスケールはAWSに完全お任せできる
* IngressからLB作成や管理、TargetGroup紐づけも任せられる
* 作成されたALBやEBS、EC2は引き続きユーザーが関与できる

実際使ってみると期待に近いものの、従来のEKS管理から見るとそこまで楽になったかは悩ましい側面もあります。また、以下2点はコンセプトから読み解けないでしょう。

* helmはどうなるのか
* podの水平スケールがどうなるのか

## EKS AddonsはAWSが管理するためユーザーは導入不要になった

これは受けた印象そのままです。EKS Addonを追加不要、Podも見えなくなったのでマネージドだなという印象と実感が揃っています。

* ✔️: これまでEKSクラスターで必須といってもよかったCoreDNS、kube-proxy、VPC CNIはAutoModeでは導入不要
* ✔️: Node LocalDNSも組み込みになった
* ✔️: CoreDNS、kube-proxy、VPC CNIのPodやリソースはAuto ModeなEKSではkubectlで見えない
* ⚠️: サードパーティEKS Addonの新Kubernetesバージョン対応は引き続き待つ必要がある

これらのAddonやコンポーネントはEKSで必須なわりに手当が全然なくてしんどさしかなったので、非常に好ましい対応です。最高!

ただ、3rdパーティのEKS Addonが利用できるかはEKSのKubernetesに依存します。例えば、現在EKS 1.32が最新ですが3rdパーティEKS Addonの多くは対応していません。悲しい。

## EC2のオートスケールはAWSに完全お任せできる

完全お任せにはできませんが、次の限定的なシーンではお任せできます。

* ✔️: EKS AutoModeはKarpenterコントローラーを組み込みで持っている
* ✔️: 任せる場合、SPOTは使わない、amd64でしかアプリケーションを動作しない、ストレージサイズは80GB固定、インスタンスタイプも任せる
* ⚠️: 上を一つでも変えたい場合、自分でKarpenterのNodeClass[^1]、NodePool定義を書く必要がある
* ⚠️: AMIは常に最新が利用される(自動パッチ)
* ⚠️: EKS AutoMode管理のKarpenterで作られたEC2は追加料金がかかる(+11-12%程度)

EKS AutoModeのノード水平スケールはほぼKarpenterそのままなので、Karpenter 1.2以上を使っている人なら戸惑うことなく自分のNodeClassやNodePool定義を書くことができます。

NodeClassはEC2NodeClassと違ってamiSelectorがなくなっています。そのため、AMIを指定せずとも最新が使われる一方で、AMIを固定することができなくなっているので注意が必要です。

気になる点はコストです。EKS AutoModeの組み込みKarpenterで起動したEC2インスタンスは追加料金が11-12%程度かかります。オンデマンド・スポットにかかわらず固定金額かかるので、単純にEKS AutoModeにするとコストが12%程度上がると考えても差支えないでしょう[^2]。

**EC2コスト増加分の個人的所感**

Karpenterコントローラー・従来EKS AddonのPodが見えないことから、EC2コスト追加料金はこれらの稼働分としてかかっているのかなと感じます。しかし、Karpenterコントローラーで2Pod動作・EKSAddon各種で6-10pod程度増える程度なので全EC2ノードに11-12%コスト上乗せするのはちょっと納得感ありません。

SPやRI、スポットでも変わらない1台当たり追加料金なので、費用低減策をしているほど重くなりますよね。

## IngressからLB作成や管理、TargetGroup紐づけも任せられる

完全お任せにはできませんが、次の限定的なシーンではお任せできます。

* ✔️: EKS AutoModeはElastiｃ Load Balancingを管理するコントローラーを組み込みで持っている
* ✔️: ALBやNLBをIngress/Serviceで管理する場合は任せられる
* ⚠️: 既存のALBをEKS AutoModeに直接マイグレートできない
* 🆖: [TargetGroupBindingに対応していない](https://github.com/aws/containers-roadmap/issues/2508)

EKS AutoModeではAWS LoadBalancer Controllerを組み込みで持っていると言及しておらずタグが違っていたり、annotationsではなくIngressClassParamsで構成調整になっているので独自の仕組みになってそうです。

もしもAWS LoadBalancer Controllerを使っている既存EKSクラスターをAuto Modeに変更してALB管理を切り替える場合、[ドキュメント](https://docs.aws.amazon.com/eks/latest/userguide/migrate-auto.html)に沿ってDNSベースのトラフィックシフト(Route53の加重ルーティング)を使うのがいいでしょう。[^3]

## 作成されたALBやEBS、EC2は引き続きユーザーが関与できる

組み込みKarpenterで作られたEC2(AutoMode管理ノード)は、ユーザーの関与が可能な側面とできなくなった側面があります。EC2を直接消せなくなったのは安全ですが、一方で夜間停止などのアプローチ方法が一つ減りました。[^4]

* ✔️: EKS AutoModeで作成されたEC2、ALB、NLB、EBSなどはユーザーのAWSコンソールで確認できる。
* ⚠️: AutoMode管理ノードはユーザーが消せない、ソフトウェア追加できない、SSHできない
* ⚠️: AutoMode管理ノードは最大21日寿命だがPDBで制御が必要

マネージドインスタンスの[ドキュメント](https://docs.aws.amazon.com/eks/latest/userguide/automode-learn-instances.html)にある通り、EKS AutoModeで起動したEC2はEKS管理下になるためパッチあて、ソフトウェアインストール、sshはできなくなっています。

特に最大21日寿命なのはワークロードを選びます。ゲームサーバーでよくある「インメモリにデータを持つサーバー」は、時にワールドサーバーと呼ばれる大量常時接続をさばき、長時間起動しっぱなしにするケースがあります。このケースではワールドサーバーの停止はゲームの停止を意味するため、サーバーの入れ替えもタイミングを選ぶことになります。そう、寿命日数とハードリミットされるのと致命的に相性が悪いんですね。

## helmはどうなるのか

AutoModeになっても、Helmは引き続きユーザー管理です。それはそう。そして、EKSで一番つらいのは実のところHelmでもあるのできつさは何も軽減していません。Helmアップグレードは地獄安定。

* ⚠️: EKS AutoModeでもユーザーが自分で導入したHelmは自分で管理が必要

3rdパーティEKS Addonにすれば楽になるとか思ってしまいそうですが、EKS AddoごとにKubernetesバージョン対応を待つ必要があります。Kubernetes 1.32への対応が3/15時点でもあまり進んでない現状からすると、引き続き自前Helmでの導入は必要なケースは多いでしょう。がんばりましょう。

## podの水平スケールがどうなるのか

AutoModeはPodの水平スケールに関与しません。Podはアプリケーションがやるべきことですから当然ですね。とはいえKEDAぐらいは入れてほしかった。HPAは厳しい。

* ⚠️: EKS AutoModeでもHPA以外はない。KEDAを使うなら自前Helm導入が必要。

# EKS AutoModeの総評

小規模な環境(開発や検証環境など)でEKS AutoModeは使いやすいと感じる一方で、大規模な環境(本番環境など)でEKS AutoModeはコスト面から説得力は持ちにくそうです。開発でEKS AutoMode、本番でEKS AutoModeとしてもコントローラーや定義の管理からすると共通化できず嬉しくないのもペインポイントです。

EKS AutoModeのコストさえ説得力を持たせられればいいのですが、現時点で大規模環境でEKS AutoModeを採用する動機付けは難しいと感じます。

## EKS AutoModeが実現していること

EKSがマネージドといってもコントロールプレーン・AWS-Kubernetesアクセス管理・ログ回りだけじゃないかという感じからすると、AutoModeはよりAWS統合を強めています。必須EKS Addonが考慮不要になりました。また、Node水平スケールアウトも組み込みKarpenterに任せることができ、AMI管理やEC2の自動更新も任せることができます。ALB/NLBとの統合も任せることができます。

## EKS AutoModeのペインポイント

EC2一台あたりのコストは+11-12%確定で上がります。ALBの安定保持のためIaCでALBを作ってアプリケーションとTargetGroupBindingでつなぐ安全策が取れません。EC2は最大21日寿命で入れ替えタイミングは制御困難です。ユーザー自身がExternalDNSやExternalSecretsのような各種コントローラーをHelmで導入している場合、Helm更新時の手間は軽減していません。PodスケールアウトはPDBしか持っていないため、時間スケールや0 replicasなどが必要ならKEDAを入れざるを得ません。

## EKS AutoModeの採用基準

KubernetesとAWS統合部分が楽になった一方でコストが上がるため、大量のEC2が必要なワークロードではコスト増加が受け入れられるかはカギになるでしょう。また、従来KarpenterやAWS LoadBalancer Controller(ALBC)をはじめとして複数Helmコントローラーを利用していたチームにとっては、Karpenter/ALBCの管理が不要になっても他のHelm管理は残るため楽になったとは感じられない[^5]のが正直なところです。

AWSコンテナ系アプリケーションで見たときに、クラスターバージョン含めた管理の楽さで`ECS Fargate > ECS EC2 >> EKS AutoMode > EKS`、コスト面で`ECS EC2 > EKS > EKS AutoScale > ECS Fargate`[^6]という感触です。

```mermaid
[フロー用意したい]
```


# EKS AutoModeを見る

EKS AutoModeが従来と決定的に違うのは次のポイントです。

1. 組み込みコンポーネントがある
2. 組み込みNodeGroupがある
3. 組み込みKarpenterで動作させるEC2は追加料金がかかる
4. 求められるIAMポリシーが異なる
5. EKS Nodeの最大Pod数が110に制限されている
6. Pod SecurityGroupが非サポート[^10]
7. カスタムネットワーキングが非サポート[^10]

一方で、通常モードとAutoModeで共通しているのは次のポイントです。

* EKSの認証方法は変わらない
* KEDAのようなPodオートスケールは組み込まれていない

順番に見ていきましょう。

## 組み込みコンポーネントがある

EKS AutoModeは

https://docs.aws.amazon.com/eks/latest/userguide/auto-upgrade.html

* Karpenterが組み込みインストールされており、Karpenterコントローラーは隠蔽されている
* AWS LoadBalancer Controllerが組み込みインストールされており、ALB Ingress Controllerは隠蔽されている
* AWS EBS CSI Driverが組み込みインストールされている
* 必須EKS Addonだったkube-proxy/CoreDNS/Amazon VPC CNIが組み込みインストールされ、Podは隠蔽されている
* EKS Pod Identity Agentが各ノードでインストールされている

## 組み込みノードグループがある

EKS AutoModeは`system`と`general-purpose`という組み込みNodeGroupがあります。従来のNodeGroupとは異なり名前が決められており、使うかどうかは任意です。

1. 組み込みノードグループはKarpenterで動作する
2. 組み込みノードグループのKarpenter定義は変更できない

## 組み込みKarpenterで動作させるEC2は追加料金がかかる

EKS AutoModeが管理するNodeに対して追加料金がかかります。一方でManaged Node Group分には追加料金がかからないようです。

> Amazon EKS Auto Mode の料金は、EKS Auto Mode によって起動および管理される Amazon EC2 インスタンスの期間とタイプに基づいてお支払いいただきます。以下の Amazon EKS Auto Mode の料金は、EC2 インスタンス自体を対象とする Amazon EC2 インスタンス料金に加えて請求されます。EC2 インスタンス料金と同様に、EKS Auto Mode の料金は 1 秒単位で課金され、1 分間分の最低料金がかかります。オンデマンド、1 年および 3 年のリザーブドインスタンス、Compute Savings Plans、スポットインスタンスなど、EKS Auto Mode では Amazon EC2 インスタンス購入オプションをすべて利用できますが、EKS Auto Mode の料金は EC2 インスタンス購入オプションとは無関係です。
>
> 引用: https://aws.amazon.com/jp/eks/pricing/

まとめると次のようになります。EKS AutoMode管理のNodeClassを使うとカウントされるようなので、逃げ道が事実上なくて厳しいものを感じます。

| 起動タイプ | 追加コストが必要 |
| --- | --- |
| EKS AutoModeのBuilt-in node poolsで起動したEC2 | 必要 |
| EKS AutoModeで自前Node ClassとNodePoolで起動したEC2 | 必要 |
| EKS AutoModeのManaged Node Groupで起動したEC2 | 不要 |
| EKS AutoModeにOSS Karpenterを入れてEC2NodeClassとNodePoolで起動したEC2 | 不要 |

追加分のコストはCost Explorer > API operationでEKSAutoUsageとして表示されます。(Service分類は`Elastic Container Service for Kubernetes`)

追加料金を試算してみましょう。例えばEKS AutoModeのBuilt-in node pools`system`が有効な状態で、EKS Addonの`Metrics Server`をインストールすると`c6g.large`が2台[^11]起動します。ap-northeast-1で起動した場合、EKS AutoModeで起動した`c6g.large`のコストは`$0.0856 (EC2オンデマンド料金) + $0.01027 (EKS AutoMode追加分) = $0.09587/h`と元の価格から見て119.9％です。
AWSの例示する料金例を見ても、おおむね+11-12％程度の追加EC2料金になると見込むことになりそうです。

![image](https://github.com/user-attachments/assets/12718e9d-d206-497a-81ce-150c9cd0f113)

![image](https://github.com/user-attachments/assets/6de4f6f6-9bd0-4942-aec1-505a776b3065)

EKS AutoModeが管理するかどうかは、EC2インスタンスなら`Managed`にTrueがついているか、Nodeなら`eks.amazonaws.com/compute-type: auto`ラベルがあるかで判別できます。

![image](https://github.com/user-attachments/assets/2193595c-021a-4d4b-8dac-fb90c9e44e1e)

Nodeにラベルがあるので、nodeSelectorやtains/tolerationsで制御はできますね。

```yaml
nodeSelectcor:
  eks.amazonaws.com/compute-type: auto
```

**組み込みノードグループのKarpenter定義は変更できない**

それぞれのNodeGroupは異なるKarpenter定義になっています。

**Auto Modeが管理するEC2は消せない**

Terminate Instanceしようとしても実行失敗します。

![image](https://github.com/user-attachments/assets/14108830-2a86-4a87-9f8b-5aacac986a66)

> Failed to terminate (delete) an instance: You are not authorized to perform this operation. User: arn:aws:sts::1234567801234:assumed-role/foo-role/bar is not authorized to perform: ec2:TerminateInstances on resource: arn:aws:ec2:ap-northeast-1:1234567801234:instance/i-04df53f6f7a5bc3d0 with an explicit deny in a resource-based policy. Encoded authorization failure message: ppuIku-省略...


## 求められるIAMポリシーが異なる

標準EKSクラスター構築時は、EKS Cluster用IAMロール、EKS Node用IAMロールが求められます。



### 組み込みKarpenterコントローラー

フィールドキーのいくつかは、Karpenterのデフォルトから変わっています。
https://docs.aws.amazon.com/eks/latest/userguide/create-node-pool.html

組み込みのNodeClass `default`

```sh
$ kubetl get nodeclass default -o yaml | kubetl neat
apiVersion: eks.amazonaws.com/v1
kind: NodeClass
metadata:
  annotations:
    eks.amazonaws.com/nodeclass-hash: "3399735243323253970"
    eks.amazonaws.com/nodeclass-hash-version: v1
  labels:
    app.kubernetes.io/managed-by: eks
  name: default
spec:
  ephemeralStorage:
    iops: 3000
    size: 80Gi
    throughput: 125
  networkPolicy: DefaultAllow
  networkPolicyEventLogs: Disabled
  role: automode-eks-AmazonEKSAutoNodeRole
  securityGroupSelectorTerms:
  - id: sg-1234567890
  snatPolicy: Random
  subnetSelectorTerms:
  - id: subnet-1234567890123
  - id: subnet-1234567890234
```

組み込みのNodePool `system`

```sh
$ kubectl get nodepool system -o yaml | kubectl neat
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  annotations:
    karpenter.sh/nodepool-hash: "4982684901400657622"
    karpenter.sh/nodepool-hash-version: v3
  labels:
    app.kubernetes.io/managed-by: eks
  name: system
spec:
  disruption:
    budgets:
    - nodes: 10%
    consolidateAfter: 30s
    consolidationPolicy: WhenEmptyOrUnderutilized
  template:
    spec:
      expireAfter: 336h
      nodeClassRef:
        group: eks.amazonaws.com
        kind: NodeClass
        name: default
      requirements:
      - key: karpenter.sh/capacity-type
        operator: In
        values:
        - on-demand
      - key: eks.amazonaws.com/instance-category
        operator: In
        values:
        - c
        - m
        - r
      - key: eks.amazonaws.com/instance-generation
        operator: Gt
        values:
        - "4"
      - key: kubernetes.io/arch
        operator: In
        values:
        - amd64
        - arm64
      - key: kubernetes.io/os
        operator: In
        values:
        - linux
      taints:
      - effect: NoSchedule
        key: CriticalAddonsOnly
      terminationGracePeriod: 24h0m0s
```

組み込みのNodePool `general-purpose`

```sh
$ kubectl get nodepool general-purpose -o yaml | kubectl neat
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  annotations:
    karpenter.sh/nodepool-hash: "4012513481623584108"
    karpenter.sh/nodepool-hash-version: v3
  labels:
    app.kubernetes.io/managed-by: eks
  name: general-purpose
spec:
  disruption:
    budgets:
    - nodes: 10%
    consolidateAfter: 30s
    consolidationPolicy: WhenEmptyOrUnderutilized
  template:
    spec:
      expireAfter: 336h
      nodeClassRef:
        group: eks.amazonaws.com
        kind: NodeClass
        name: default
      requirements:
      - key: karpenter.sh/capacity-type
        operator: In
        values:
        - on-demand
      - key: eks.amazonaws.com/instance-category
        operator: In
        values:
        - c
        - m
        - r
      - key: eks.amazonaws.com/instance-generation
        operator: Gt
        values:
        - "4"
      - key: kubernetes.io/arch
        operator: In
        values:
        - amd64
      - key: kubernetes.io/os
        operator: In
        values:
        - linux
      terminationGracePeriod: 24h0m0s
```

### 組み込みAWS LoadBalancer Controller

https://docs.aws.amazon.com/eks/latest/userguide/auto-networking.html

networking.ingress.ipBlock仕様内のフィールドはTargetGroupBindingサポートされていません。

### 組み込みAWS EBS CSI Driver


## EKS Nodeの最大Pod数は110台制限

ハードリミットな制限になっています。

https://docs.aws.amazon.com/eks/latest/userguide/choosing-instance-type.html

##

EKS Auto ModeのNodeClassリソース`default`を利用するいくつかの制約がでます。特にこの辺りは注意です。

* Pod SecurityGroupをサポートしていない
* カスタムネットワーキングをサポートしていない
* conntrackのカスタマイズ(デフォルト300秒)

EKS Auto ModeのポッドとノードのIPアドレスは「同じCIDRブロックからのもの」である必要があります。[カスタムネットワーキング](https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/cni-custom-network.html)をサポートしていないということは、運用中にVPCへ追加CIDRを設定、サブネットを切ってPodを起動させるということができません。カスタムネットワーキングはIPv4でしかサポートされてなかった機能とはいえ、ちょっと困りますね。

**ワークアラウンド**

カスタムネットワーキングが利用できない制約は、EKS Auto ModeのNodeClassがEKSクラスターと同じSubnetIdを固定参照していることに起因しています。
このため、カスタムでEC2NodeClassを作成して`タグでサブネットを探索`させればこの制約は回避できます。



# EKS AutoModeの動作を試す

## カスタムNodeClassとNodePoolを展開する


EBSサイズが20GiBになっていますね。

![image](https://github.com/user-attachments/assets/7f300de6-e32f-4f6e-b473-26fa91db131e)


## NodeClassの注意

**spec.roleは64文字未満である必要がある**

spec.roleのIAM Role名は64文字未満である必要があります。

```sh
$ kubectl apply -f ./k8s/test/automode_nodepool.yaml
The NodeClass "custom-class" is invalid:
* spec.role: Too long: may not be more than 64 bytes
* <nil>: Invalid value: "null": some validation rules were not checked because the object was invalid; correct the existing errors to complete validation
```

[ドキュメント](https://docs.aws.amazon.com/eks/latest/userguide/create-node-class.html)がIAM Role ARNになっているのでびっくりしますが、実際は名前なのでセーフです。

```yaml
spec:
  # ×: ドキュメントはIAM Role ARN表記になっている
  role: arn:aws:iam::123456789012:role/MyNodeRole
  # 〇: 実際はIAM Role NAmeでOK。OSS Karpenterと同じ
  role: MyNodeRole
```

**追加タグを設定するには追加権限が必要**

NodeClaimが展開出来ずdescribeすると次の表示になっていることがあります。

```sh
$ kubectl describe nodeclaim xxxxx

Status:
  Conditions:
    Last Transition Time:  2025-03-12T09:48:38Z
    Message:               object is awaiting reconciliation
    Observed Generation:   1
    Reason:                AwaitingReconciliation
    Status:                Unknown
    Type:                  Initialized
    Last Transition Time:  2025-03-12T09:48:38Z
    Message:               Error getting launch template configs: User is not authorized to perform this operation because no identity-based policy allows it
    Observed Generation:   1
    Reason:                Unauthorized
    Status:                Unknown
    Type:                  Launched
    Last Transition Time:  2025-03-12T09:48:38Z
    Message:               Node not registered with cluster
    Observed Generation:   1
    Reason:                NodeNotFound
    Status:                Unknown
    Type:                  Registered
    Last Transition Time:  2025-03-12T09:48:38Z
    Message:               Initialized=Unknown, Launched=Unknown, Registered=Unknown
    Observed Generation:   1
    Reason:                ReconcilingDependents
    Status:                Unknown
    Type:                  Ready
Events:                    <none>
```

原因は、NodeClassで追加タグを設定していることです。この場合、[追加権限](https://docs.aws.amazon.com/eks/latest/userguide/auto-learn-iam.html#tag-prop)がEKS AutoModeクラスターのIAM Roleに必要です。

```yaml
apiVersion: eks.amazonaws.com/v1
kind: NodeClass
metadata:
  name: foo
spec:
  # 省略
  tags:
    environment: custom
```

設定すれば無事にNodeClaimが展開されて、EC2が起動、Podがスケジュールされます。

## NodePoolの注意

**expireAfterにNeverは設定できない**

spec.template.spec.expireAfterにNeverを設定するとエラーになります。

```sh
$ kubectl apply -f ./k8s/test/automode_nodepool.yaml
Error from server (Invalid): error when creating "./k8s/test/automode_nodepool.yaml": NodePool.karpenter.sh "custom-pool" is invalid: [spec.template.spec: Invalid value: "object": type conversion error from 'string' to 'google.protobuf.Duration' evaluating rule: the sum of expireAfter and terminationGracePeriod may not exceed 21 days, spec.template.spec: Invalid value: "object": expireAfter may not be set to Never]
```


## 追加EKS Addonをインストールする

追加EKS Addonをインストールすると、組み込みNodeGroupの`system`が利用されます。

# 参考

* [Amazon EKS Auto Mode の発表 | AWS](https://aws.amazon.com/jp/about-aws/whats-new/2024/12/amazon-eks-auto-mode/)
* [EKS Auto Mode | Spearker Deck](https://speakerdeck.com/kashinoki38/eks-auto-mode)
* https://medium.com/@kazioyazi/nodeclaim-has-error-error-getting-launch-template-configs-in-eks-auto-mode-46edca067fba

[^1]: KarpenterのEC2NodeClassに相当しますが、EKS AutoModeでは設定できるフィールドに制限があります
[^2]: ECSもFargateだとお高くなりがちなのと似ていますが、ECS EC2では追加コストないので割と非対称にも思います。
[^3]: 自分で[LCUを設定できる](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/capacity-unit-reservation.html)ようになってよかったよかった。
[^4]: Managed NodeGroupを0台にして、Karpenterで起動したEC2を強制的にTerminateすることで簡単に夜間停止を用意できたのが不可能になった
[^5]: そもそもHelmコントローラーの更新がつらいので0にしたい
[^6]: EKS with Fargateはコスト面で最も悪いですが同軸には適さないので除外
[^10]: https://docs.aws.amazon.com/eks/latest/userguide/auto-networking.html
[^11]: 2台起動するのは、Metrics ServerのpodAntiAffinityで`affinity.podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution`にて`"topologyKey": "kubernetes.io/hostname"`が設定されているため同一Nodeでスケジュールされないため



https://dev.classmethod.jp/articles/create-eks-auto-mode-cluster-by-terraform/
https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/main.tf
https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/create-node-pool.html
https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/automode-get-started-console.html


https://docs.aws.amazon.com/eks/latest/userguide/automode-learn-instances.html
https://aws.amazon.com/jp/ec2/instance-types/
https://docs.aws.amazon.com/eks/latest/userguide/auto-learn-iam.html#tag-prop
https://docs.aws.amazon.com/eks/latest/userguide/auto-networking.html
https://karpenter.sh/docs/concepts/nodeclasses/
https://docs.aws.amazon.com/eks/latest/userguide/automode-workload.html
https://docs.aws.amazon.com/eks/latest/userguide/choosing-instance-type.html
https://dev.classmethod.jp/articles/eks-auto-mode-custom-node-pool/
https://zenn.dev/fy0323/articles/4d64ebd5195cdd
https://speakerdeck.com/kashinoki38/eks-auto-mode?slide=47
https://karpenter.sh/docs/concepts/nodeclasses/
https://docs.aws.amazon.com/eks/latest/userguide/community-addons.html
https://github.com/aws/containers-roadmap/issues/2508
https://docs.aws.amazon.com/eks/latest/userguide/automode-learn-instances.html
