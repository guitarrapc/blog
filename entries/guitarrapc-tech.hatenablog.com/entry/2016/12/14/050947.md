---
Title: Amazon Athena で S3 Access Log を分析する
Category:
- AWS
Date: 2016-12-14T05:09:47+09:00
URL: https://tech.guitarrapc.com/entry/2016/12/14/050947
EditURL: https://blog.hatena.ne.jp/guitarrapc_tech/guitarrapc-tech.hatenablog.com/atom/entry/10328749687198902465
---

re:Invent 2016 は AWS の利用が一段回上に上がる素晴らしい発表が多かったです。さて今回取り上げるのは Athena です。

[f:id:guitarrapc_tech:20161214042640p:plain]

> - [https://aws.amazon.com/jp/blogs/news/amazon-athena-interactive-sql-queries-for-data-in-amazon-s3/:title]

すでに素晴らしい資料があるのでそちらをご参照ください。ざっくり個人的な理解は、Google BigQuery の AWS版 という雑な印象です。

[https://www.slideshare.net/GanotaIchida/re-growth2016osaka-amazonathena-70077024:embed:cite]



[https://data.gunosy.io/entry/aws-athena-vs-bigquery:embed:cite]



今回は S3 を Static website hosting している場合の S3 アクセスログを Athena で分析してみましょう。ELBとか CloudTrail はあるのに、S3 Access Log の記事見つからないものですね。

なお、この記事は以下のフォーマットを対象にしているため、フォーマットが将来変更された場合に動かないことがありえます。あらかじめご了承ください。

[https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/LogFormat.html:embed:cite]

```
1234abcd1234abcd1234abcd1234abcd1234abcd1234abcd1234abcd1234abcd hogemogeTestTest.contoso.com [07/Dec/2016:05:59:12 +0000] 191.1.1.2 1234abcd1234abcd1234abcd1234abcd1234abcd1234abcd1234abcd1234abcd 667C2B96205F407E REST.GET.VERSIONING  - "GET /hogemogeTestTest.contoso.com?tagging HTTP/1.1" 404 NoSuchTagSet 285 - 45 - "-" "S3Console/0.4" -
```


[:contents]

# S3 バケットの状態

Athena は **US East (Virginia)** と **US West (Oregon)** のみで選択できるサービスですが、対象となるS3 はその制約がありません。当然ですね。

[f:id:guitarrapc_tech:20161214043009p:plain]

さて、Athena の対象となる S3 バケットを Static website hosting として用意します。

[f:id:guitarrapc_tech:20161214043536p:plain]

Logging を有効にしておいて事前にログが吐かれた状態にしましょう。今回は、`BucketName/logs` に吐くようにしました。

[f:id:guitarrapc_tech:20161214043551p:plain]

[f:id:guitarrapc_tech:20161214043743p:plain]

このような構成だと思ってください

バケット名 | ログパス
---- | ----
hogemogeTestTest.contoso.com | logs/

この状態で logs フォルダをみると.... 絶望ですね。これを手やAPI で見ようというのは人間のやることではなくなりました。Athena を使うのです。

[f:id:guitarrapc_tech:20161214043904p:plain]

# Athenaの処理

さて分析対象が定まったので Athena にDBとテーブルを用意して分析しましょう。作成する内容は次の通りですね。

対象バケット名 | Athena データベース名 | Athena テーブル名
---- | ---- | ----
s3://hogemogeTestTest.contoso.com/logs/ | s3_AccessLogsDB | hogemogeTestTest_contoso_com

対象バケット名ですが、作成ウィザードではリージョンが必要そうなブランク欄の薄い灰色表示ですが、リージョンは不要です。

[f:id:guitarrapc_tech:20161214044546p:plain]

では早速見てみましょう。今回は パーティションを省いてクエリ (HiveQL) のみで一気に行きます。


##### データベースの作成

まずは、Athena でS3AccessLogに関するデータベース **s3_AccessLogsDB** を作成します。すでにデータベースがあるならここはスキップしていただいてok です。

[f:id:guitarrapc_tech:20161214044048p:plain]

[https://gist.github.com/guitarrapc/ed1bffa78dcac37f5b72d76f4a97ad87:embed:cite]

実行を待ってねと出て上手く作成できました。

[f:id:guitarrapc_tech:20161214044657p:plain]

ちなみに`CREATE DATABASE` 文と 後述する `CREATE DATABASE` 文は同時に投げることはできません。1つずつ投入、実行してください。

##### テーブル定義の作成

お次はテーブル定義です。

S3 Access Log のログ形式は次の通りです。

[https://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/LogFormat.html:embed:cite]

さてフォーマットのシリアライザはどれが使えるでしょうか。

> - [https://aws.amazon.com/jp/athena/faqs/:title]

一見 `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe` がよさそうですがクォートのサポートがないので、今回は `org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe` を使ってごりごりやります。

[https://gist.github.com/guitarrapc/c07bd7dc52935aee36e78ac178ef940d:embed:cite]

2点だけ説明をした方がよさそうなので触れておきます。

1. `s3_accesslogsdb.hogemogeTestTest_contoso_com` は、`s3_accesslogsdb.hogemogeTestTest_contoso_com` としています。お好きに書き換えてください
1. Location にある `s3://hogemogeTestTest.contoso.com/logs/` が対象の S3バケット名です

これで実行すると、上手くテーブルが作られたはずです。

[f:id:guitarrapc_tech:20161214050522p:plain]

[f:id:guitarrapc_tech:20161214050530p:plain]

テーブルプロパティをみてみます。

[f:id:guitarrapc_tech:20161214050636p:plain]

適当なクエリで中身を見てもうまくいっていますね。

```sql
SELECT * FROM hogemogetesttest_contoso_com limit 10;
```

[f:id:guitarrapc_tech:20161214050808p:plain]

あとは任意のクエリで分析しましょう。

[https://dev.classmethod.jp/cloud/aws/amazon-athena-sqls/:embed:cite]

# まとめ

Athena がきたことでようやく S3 にエコシステムが出来てよかったですね！

ちょくちょく使ったりデータ量が多いなら パーティションを貼っておいた方が精神安定上いいと思います。
