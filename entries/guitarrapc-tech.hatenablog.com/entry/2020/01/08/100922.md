---
Title: Datadog Log Management で Kubernetes の external-dns やkube2iam のログレベルを適切に扱いたい
Category:
- Monitoring
- Logging
- Kubernetes
Date: 2020-01-08T10:09:22+09:00
URL: https://tech.guitarrapc.com/entry/2020/01/08/100922
EditURL: https://blog.hatena.ne.jp/guitarrapc_tech/guitarrapc-tech.hatenablog.com/atom/entry/26006613494760520
---

Kubernetesのログを見るといえば、Datadog Log Mangementが楽なのですが時々ログメッセージが適切なレベルで扱われません。

そんなときによくやる「ログメッセージからレベルになるフィールドを取り出してLog Statusとして認識させる」ことを見てみましょう。

<figure class="figure-image figure-image-fotolife" title="Before">[f:id:guitarrapc_tech:20200108100711p:plain]<figcaption>Before</figcaption></figure>

<figure class="figure-image figure-image-fotolife" title="After">[f:id:guitarrapc_tech:20200108100721p:plain]<figcaption>After</figcaption></figure>

[:contents]

## TL;DR

* Custom Pipelineを使って、ログメッセージを構造化とLog Statusの変更すればok
* ログメッセージが`key=value`で構造化されているとさくさく構築できるので神

## 問題

Kubernetesに限らず、Log Managementでログを取り込んだ時に意図と違ったログレベルとして認識されることがあります。

たとえばKubernetesでexternal-dnsを使っているとき、実行するものがないときは`All records are already up to date`というメッセージ出力されるのですが、Datadog Log ManagementではStatusがErrorとなっています。

```
level=info msg="All records are already up to date"
```

しかしこのログは、Messageに`level=info`とある通りエラーログではありません。
これをInfoとして扱いたいのでさくっと対処しましょう。

## ログを見てみる

まずはログがどう認識されているのか見てみましょう。

<figure class="figure-image figure-image-fotolife" title="何も実行するものがないときのログ">[f:id:guitarrapc_tech:20200108100351p:plain]<figcaption>何も実行するものがないときのログ</figcaption></figure>

対象のログを見てみると、Log StatusがErrorとなっていることがわかります。

<figure class="figure-image figure-image-fotolife" title="Log Status が Error">[f:id:guitarrapc_tech:20200108100325p:plain]<figcaption>Log Status が Error</figcaption></figure>

また、ログも構造化されていません。

<figure class="figure-image figure-image-fotolife" title="ログが構造化されていない">[f:id:guitarrapc_tech:20200108100217p:plain]<figcaption>ログが構造化されていない</figcaption></figure>

## 対処法針

external-dnsのログは、`level` keyでログレベルを表現しています。
こういったログへの追加対応は、Log ManagementのPipelineに追加のカスタムパイプラインを追加できます。
パイプラインには様々な処理(Processor)を設定できます。
今回はデフォルトのパイプラインで設定されたログレベルを書き換えたいので、`Log Status Remapper`を用いることでログに含まれる`level`キーの値をLog Statusとして認識させることができます。

> Use this Processor if you want to assign some attributes as the official status. For example, it can transform this log:

<figure class="figure-image figure-image-fotolife" title="before">[f:id:guitarrapc_tech:20200108094843p:plain]<figcaption>before</figcaption></figure>

<figure class="figure-image figure-image-fotolife" title="after">[f:id:guitarrapc_tech:20200108094853p:plain]<figcaption>after</figcaption></figure>

> [Log status remapper - Datadog](https://docs.datadoghq.com/logs/log_configuration/processors/?tab=ui#log-status-remapper)

対応方針は次の通りです。

* 新規パイプランを作る
* ログメッセージがただの文字列として扱われているのでJSONとして認識されるように構造化
* 構造化したデータから対象の`level` keyを拾ってLog Statusを書き換える

## パイプライン対応

Custom Pipelineを追加して、2つProcessorを追加していきます。

### Custom Pipeline の追加

Datadog AgentのPipelineの後ろに新規Pipelineを追加します。

パイプラインを作成するときに、対象となるログを絞り込みます。
今回は`All records are already up to date`となっているログを絞りたいので、Sourceとメッセージで指定してみましょう。

```
source:external-dns message:"*All records are already up to date"
```

### Processor の追加: Grok Parserで構造化する

パイプラインができたら、具体的な処理単位であるProcessorを追加します。
まずは、ただの文字列になっているログを構造化 (JSON) 変換するため、Grok Parserを用います。

> [Grok Parser - Datadog](https://docs.datadoghq.com/logs/log_configuration/processors/?tab=ui#grok-parser)

変換方法を考えるため、対象にしたいログメッセージを見てみましょう。

```
time="2020-01-07T09:49:07Z" level=info msg="All records are already up to date"
```

今回のログは「`key=value`がスペースで羅列されている構造」とわかります。
こういった、文字列が`key{何かの文字}value`で構成されている場合、`%{data::keyvalue}`を使うだけでサクッと構造化できます。

```
external_dns_rule %{data::keyvalue}
```

> [Key value or logfmt - Datadog](https://docs.datadoghq.com/logs/log_configuration/parsing/?tab=matchers#key-value-or-logfmt)

これでいい感じのJSONに変換されてました。

```json
{
  "time": "2020-01-07T09:49:07Z",
  "level": "info",
  "msg": "All records are already up to date"
}
```

<figure class="figure-image figure-image-fotolife" title="Grok Parser で構造化">[f:id:guitarrapc_tech:20200108095407p:plain]<figcaption>Grok Parser で構造化</figcaption></figure>

### Processor の追加: Log Status Remapperでログステータスとする

構造化したデータからステータスをとります。
もう一度Processorを追加して、今度は`Log Status Remapper`を使ってログステータスの差し替えを行います。

> [Log status remapper - Datadog](https://docs.datadoghq.com/logs/log_configuration/processors/?tab=ui#log-status-remapper)

`level`キーの値を使うので、対象キーに`level`を指定します。

<figure class="figure-image figure-image-fotolife" title="Log Status Remapper で level キーを用いる">[f:id:guitarrapc_tech:20200108095722p:plain]<figcaption>Log Status Remapper で level キーを用いる</figcaption></figure>

これでおしまいます。

## Pipelineの結果を確認

Log Explorerでログの結果を見てみると、いい感じにStatusが変わったことと確認できます。

[f:id:guitarrapc_tech:20200108100010p:plain]

先ほどなにもデータがなかったATTRIBUTESにも、変換した構造化データがのっていることがわかります。

このパターンはちょくちょく使うので、さくっとできると捗るでしょう。

## REF

[https://github.com/kubernetes-sigs/external-dns/issues/772:embed:cite]
